Intelligence artificielle faible[modifier | modifier le code]
Article détaillé : Intelligence artificielle faible.
La notion d’intelligence artificielle faible constitue une approche pragmatique d’ingénieur : chercher ŕ construire des systčmes de plus en plus autonomes (pour réduire le coűt de leur supervision), des algorithmes capables de résoudre des problčmes d’une certaine classe, etc. Mais, cette fois, la machine simule l'intelligence, elle semble agir comme si elle était intelligente. On en voit des exemples concrets avec les programmes conversationnels qui tentent de passer le test de Turing, comme ELIZA. Ces logiciels parviennent ŕ imiter de façon grossičre le comportement d'humains face ŕ d'autres humains lors d'un dialogue.
Joseph Weizenbaum, créateur du programme ELIZA, met en garde le public dans son ouvrage Computer Power and Human Reason : si ces programmes « semblent » intelligents, ils ne le sont pas : ELIZA simule trčs grossičrement un psychologue en relevant immédiatement toute mention du pčre ou de la mčre, en demandant des détails sur tel élément de phrase et en écrivant de temps en temps « Je comprends. », mais son auteur rappelle qu'il s'agit d'une simple mystification : le programme ne comprend en réalité rien.
Les tenants de l'IA forte admettent que s'il y a bien dans ce cas simple simulation de comportements intelligents, il est aisé de le découvrir et qu'on ne peut donc généraliser. En effet, si on ne peut différencier expérimentalement deux comportements intelligents, celui d'une machine et celui d'un humain, comment peut-on prétendre que les deux choses ont des propriétés différentes ? Le terme męme de « simulation de l'intelligence » est contesté et devrait, toujours selon eux, ętre remplacé par « reproduction de l'intelligence ».
Les tenants de l'IA faible arguent que la plupart des techniques actuelles d’intelligence artificielle sont inspirées de leur paradigme. Ce serait par exemple la démarche utilisée par IBM dans son projet nommé Autonomic computing. La controverse persiste néanmoins avec les tenants de l'IA forte qui contestent cette interprétation.
Simple évolution, donc, et non révolution : l’intelligence artificielle s’inscrit ŕ ce compte dans la droite succession de ce qu’ont été la recherche opérationnelle dans les années 1960, la supervision (en anglais : process control) dans les années 1970, l’aide ŕ la décision dans les années 1980 et le data mining dans les années 1990. Et, qui plus est, avec une certaine continuité.
Il s'agit surtout d'intelligence humaine reconstituée, et de programmation ad hoc d'un apprentissage, sans qu'une théorie unificatrice n'existe pour le moment (2011). Le Théorčme de Cox-Jaynes indique toutefois, ce qui est un résultat fort, que sous cinq contraintes raisonnables, tout procédé d'apprentissage devra ętre soit conforme ŕ l'inférence bayésienne, soit incohérent ŕ terme, donc inefficace65.
Estimation de faisabilité[modifier | modifier le code]
Le sémanticien François Rastier, aprčs avoir rappelé les positions de Turing et de Grice ŕ ce sujet, propose66 six « préceptes » conditionnant un systčme de dialogue évolué, en précisant qu'elles sont déjŕ mises en śuvre par des systčmes existants :
objectivité (utilisation d'une base de connaissance par le systčme) ;
textualité (prise en compte d'interventions de plus d'une phrase, qu'elles émanent du systčme ou de l'utilisateur) ;
apprentissage (intégration au moins temporaire d'informations issues des propos de l'utilisateur) ;
questionnement (demande de précisions de la part du systčme) ;
rectification (suggestion de rectifications ŕ la question posée, lorsque nécessaire) ;
explicitation (explicitation par le systčme d'une réponse qu'il a apportée précédemment).
Il suggčre aussi que le systčme devrait ętre en mesure de se faire par lui-męme une représentation de l'utilisateur auquel il a affaire, pour s'adapter ŕ lui. De son côté, l'utilisateur a tendance ŕ s'adapter au systčme ŕ partir du moment oů il a bien compris qu'il s'adresse ŕ une machine : il ne conversera pas de la męme maničre avec un systčme automatisé qu'avec un interlocuteur humain, ce qui présente pour le concepteur l'avantage pragmatique de simplifier certains aspects du dialogue.
Courants de pensée[modifier | modifier le code]
La cybernétique naissante des années 1940 revendiquait trčs clairement son caractčre pluridisciplinaire et se nourrissait des contributions les plus diverses : neurophysiologie, psychologie, logique, sciences sociales… Et c’est tout naturellement qu’elle envisagea deux approches des systčmes, deux approches reprises par les sciences cognitives et de ce fait l’intelligence artificielle : une approche par la décomposition (du haut vers le bas) et une approche contraire par construction progressive du bas vers le haut.
Ces deux approches se révčlent plutôt complémentaires que contradictoires : on est ŕ l'aise pour décomposer rapidement ce que l'on connaît bien, et une approche pragmatique ŕ partir des seuls éléments que l'on connaît afin de se familiariser avec les concepts émergents est plus utile pour les domaines inconnus. Elles sont respectivement ŕ la base des hypothčses de travail que constituent le cognitivisme et le connexionnisme, qui tentent aujourd'hui (2005) d'opérer progressivement leur fusion.
Le HOWTO de Linux sur l'intelligence artificielle v3.067, révisé le 15 décembre 2012, adopte pour la commodité du lecteur la taxinomie suivante :
Systčmes symboliques ;
Connexionnisme ;
Calcul évolutif (algorithmes génétiques, par exemple) ;
Alife (vie artificielle) et Complexité ;
Agents et robotique.
Cognitivisme[modifier | modifier le code]
Le cognitivisme considčre que le vivant, tel un ordinateur (bien que par des procédés évidemment trčs différents), manipule essentiellement des symboles élémentaires. Dans son livre La société de l’esprit, Marvin Minsky, s’appuyant sur des observations du psychologue Jean Piaget, envisage le processus cognitif comme une compétition d’agents fournissant des réponses partielles et dont les avis sont arbitrés par d’autres agents. Il cite les exemples suivants de Piaget :
L’enfant croit d’abord que plus le niveau d’eau est élevé dans un verre, plus il y a d’eau dans ce verre. Aprčs avoir joué avec des transvasements successifs, il intčgre le fait que la notion de hauteur du liquide dans le verre entre en compétition avec celle du diamčtre du verre, et arbitre de son mieux entre les deux.
Il vit ensuite une expérience analogue en manipulant de la pâte ŕ modeler : la réduction de plusieurs objets temporairement représentés ŕ une męme boule de pâte l’incite ŕ dégager un concept de conservation de la quantité de matičre.
Au bout du compte, ces jeux d’enfants se révčlent essentiels ŕ la formation de l’esprit, qui dégagent quelques rčgles pour arbitrer les différents éléments d’appréciation qu’il rencontre, par essais et erreurs.
Connexionnisme[modifier | modifier le code]
Le connexionnisme, se référant aux processus auto-organisationnels, envisage la cognition comme le résultat d’une interaction globale des parties élémentaires d’un systčme. On ne peut nier que le chien dispose d'une sorte de connaissance des équations différentielles du mouvement, puisqu’il arrive ŕ attraper un bâton au vol. Et pas davantage qu’un chat ait aussi une sorte de connaissance de la loi de chute des corps, puisqu’il se comporte comme s’il savait ŕ partir de quelle hauteur il ne doit plus essayer de sauter directement pour se diriger vers le sol. Cette faculté qui évoque un peu l’intuition des philosophes se caractériserait par la prise en compte et la consolidation d’éléments perceptifs dont aucun pris isolément n’atteint le seuil de la conscience, ou en tout cas n’y déclenche d’interprétation particuličre.
Synthčse[modifier | modifier le code]
Trois concepts reviennent de façon récurrente dans la plupart des travaux :
la redondance (le systčme est peu sensible ŕ des pannes ponctuelles) ;
la réentrance (les composants s'informent en permanence entre eux ; cette notion diffčre de la réentrance en programmation) ;
la sélection (au fil du temps, les comportements efficaces sont dégagés et renforcés).
Différentes facettes[modifier | modifier le code]
On peut considérer différents dispositifs intervenant, ensemble ou séparément, dans un systčme d’intelligence artificielle tels que :
le dialogue automatique : se faire comprendre en lui parlant ;
la traduction automatique, si possible en temps réel ou trčs légčrement différé ;
le traitement automatique du langage naturel ;
le raisonnement automatique (voir systčmes experts) ;
l’apprentissage automatique ;
la composition musicale automatique (voir les travaux de René-Louis Baron et de l'Ircam) ;
la reconnaissance de formes, des visages et la vision en général, etc. ;
l'intégration automatique d’informations provenant de sources hétérogčnes, (fusion de données) ;
l'émotion artificielle (voir les travaux de Rosalind Picard sur l'émotion) et l'éventualité d'une subjectivité artificielle ;
etc.
Les réalisations actuelles de l’intelligence artificielle peuvent intervenir dans les fonctions suivantes :
l'aide aux diagnostics ;
l'aide ŕ la décision ;
la résolution de problčmes complexes, tels que les problčmes d'allocation de ressources ;
l'assistance par des machines dans les tâches dangereuses, ou demandant une grande précision ;
l'automatisation de tâches ;
etc.
Conception de systčmes[modifier | modifier le code]
Au fil du temps, certains langages de programmation se sont avérés plus commodes que d’autres pour écrire des applications d’intelligence artificielle. Parmi ceux-ci, Lisp et Prolog furent sans doute les plus médiatisés. ELIZA (le premier agent conversationnel, donc pas de la « véritable » intelligence artificielle) tenait en trois pages de SNOBOL. On utilise aussi, plus pour des raisons de disponibilité et de performance que de commodité, des langages classiques tels que C ou C++. Lisp a eu pour sa part une série de successeurs plus ou moins inspirés de lui, dont le langage Scheme et les langages typés de la programmation fonctionnelle comme Haskell ou OCaml.
Des programmes de démonstration de théorčmes géométriques simples ont existé dčs les années 1960 ; et des logiciels tels que Maple ou Mathematica effectuent aujourd’hui des travaux d’intégration symbolique qui, il y a trente ans encore, étaient du ressort d’un étudiant de mathématiques supérieures.
Domaines d’application[modifier | modifier le code]

Un robot NAO en 2014.

Un assistant personnel intelligent fournissant un service client sur une page d'un site web, l'une des nombreuses applications trčs primitives de l'intelligence artificielle.
L'intelligence artificielle a été utilisée (ou intervient) dans une variété de domaines.
Finance et banques[modifier | modifier le code]
la banque, avec des systčmes experts d'évaluation de risque lié ŕ l'octroi d'un crédit (credit-scoring)[réf. souhaitée] ;
la finance avec des projets comme ceux de Bridgewater Associates oů une intelligence artificielle va gérer entičrement un fonds68 ou encore la plateforme d'analyse prédictive Sidetrade ;
Militaire[modifier | modifier le code]
Le domaine militaire utilise des systčmes tels que les drones, les systčmes de commandement et d'aide ŕ la décision.
L’utilisation des intelligences artificielles dans le domaine militaire est devenu de plus en plus important. Les États-Unis ont dépensé 18 milliards de dollars pour trois années de recherches dans tous les domaines requis ŕ l’automatisation de l’armement militaire69.
Une course aux armements ŕ base d'IA est en cours, tel qu'illustré par le projet Maven aux États-Unis70.
Médecine[modifier | modifier le code]
la médecine, avec les systčmes experts d'aide au [[Diagnostic (médecine)|diagnostic[réf. souhaitée]]] ;
Droit[modifier | modifier le code]
le droit, dans la perspective de prédire les décisions de justice, d'aider ŕ la décision et de trancher les cas simples[réf. souhaitée] ;
Logistique et transports[modifier | modifier le code]
la logistique, au travers d'approches heuristiques de type résolution de [[problčme de satisfaction de contraintes|problčme de satisfaction de contraintes[réf. souhaitée]]] ;
Robotique[modifier | modifier le code]
la robotique[réf. souhaitée]
Jeux vidéo[modifier | modifier le code]
L'intelligence artificielle a par exemple été utilisée depuis longtemps dans la conception de joueurs artificiels pour le jeu d'échecs. Toutefois, c'est dans les jeux vidéo que l'intelligence artificielle s'est le plus popularisée.
Celle-ci bénéficie en effet des progrčs de l'informatique, avec par exemple les cartes graphiques dédiées qui déchargent le processeur principal des tâches graphiques. Le processeur principal peut désormais ętre utilisé pour développer des systčmes d’IA plus perfectionnés. Par exemple, l'intelligence artificielle peut ętre utilisée pour « piloter » des bots (c'est-ŕ-dire les personnages artificiels) évoluant dans les MMOGs ou les mondes virtuels, mais on peut aussi citer son utilisation dans des jeux de simulation, ou pour animer des personnages artificiels.
Dans le domaine du jeu vidéo, l’IA caractérise toute prise de décision d’un personnage (ou d’un groupe) géré par le jeu, et contraint par l’intéręt ludique : une « meilleure » IA ne donne pas forcément un jeu plus jouable71, l’objectif est de donner l’illusion d’un comportement intelligent71. L'éventail de sujets (recherche de chemin, animation procédurale, planifications stratégiques…) sont réalisables par des techniques classiques issues de l'IA symbolique (automates, script, systčmes multi-agents…), fortement dépendante de l’expertise humaine72. Cette approche est préférée par rapport aux techniques d'intelligence artificielle plus académiques (réseaux de neurones, algorithmes génétiques), car mieux contrôlée73. Ces approches partagent toutes les męmes contraintes de ressources restreintes, que ce soit en mémoire, en temps de développement, ou en temps de calcul, męme si globalement ces ressources augmentent plus les projets sont récents73.
Jusqu'ŕ la fin des années 1990, l’IA dans les jeux vidéo (plus particuličrement dans les jeux de stratégie en temps réel) a été délaissée par rapport au rendu visuel et sonore. L’« évolution vers des univers toujours plus réalistes, leur peuplement par des personnages […] aux comportements crédibles devient une problématique importante »72. Pour éviter ce contraste, et coupler dans le męme temps au délestage d’une grosse partie de l’aspect graphique des processeurs vers les cartes graphiques74, on constate ŕ cette période une augmentation des ressources investies dans l’IA (temps de développement, ressource processeur)74. Certains jeux sont précurseurs (Creatures, Black and White) car l’IA y constitue l’élément central ludique[réf. nécessaire]. Partant d’une approche ŕ base de rčgles rigides, les jeux utilisent alors des IA plus flexibles, diversifiant les techniques mises en śuvre71. Aujourd'hui la plupart des jeux vidéo utilisent des solutions ad hoc, il existe néanmoins des solutions middleware et également des solutions matérielles75 toutefois trčs minoritaires[réf. nécessaire].
Avec les jeux en réseau, le besoin d’IA a tout d’abord été négligé74, mais, particuličrement avec l’apparition des jeux massivement multijoueur, et la présence d’un nombre trčs important de joueurs humains se confrontant ŕ des personnages non joueur, ces derniers ont un besoin trčs important de pouvoir s'adapter ŕ des situations qui ne peuvent ętre prévues. Actuellement ces types de jeux intéressent particuličrement des chercheurs en IA, y trouvant un environnement adéquat pour y éprouver différentes architectures adaptatives72.
L'« IA scriptée » est une forme d'intelligence artificielle sans apprentissage, du type : « si le joueur a telle position, alors faire prendre tel chemin ŕ deux PNJ », sans que le logiciel sache que cela encercle le joueur, ou ne varie sa stratégie.
Autres domaines[modifier | modifier le code]
Il lui reste ŕ faire, entre autres, en intelligence artificielle faible :
générateur de film complet, en image de synthčse, de A ŕ Z, ŕ partir des souhaits des utilisateurs.[pertinence contestée][réf. souhaitée]
robot employé de maison[réf. souhaitée]
le débogage informatique[réf. souhaitée]
en programmation informatique[réf. souhaitée]
en journalisme : des « robots journalistes » pourraient ŕ terme aider les journalistes en les débarrassant de tâches ingrates, notamment la veille ou la vérification des fake news76.
Précurseurs[modifier | modifier le code]
Si les progrčs de l’intelligence artificielle sont récents, ce thčme de réflexion est tout ŕ fait ancien, et il apparaît réguličrement au cours de l’histoire. Les premiers signes d’intéręt pour une intelligence artificielle et les principaux précurseurs de cette discipline sont les suivants.
Automates[modifier | modifier le code]
Article connexe : Automate.
Une des plus anciennes traces du thčme de « l’homme dans la machine » date de 800 avant notre čre, en Égypte. La statue du dieu Amon levait le bras pour désigner le nouveau pharaon parmi les prétendants qui défilaient devant lui, puis elle « prononçait » un discours de consécration. Les Égyptiens étaient probablement conscients de la présence d’un prętre actionnant un mécanisme et déclarant les paroles sacrées derričre la statue, mais cela ne semblait pas ętre pour eux contradictoire avec l’incarnation de la divinité. Vers la męme époque, Homčre, dans L'Iliade (XVIII, 370–421), décrit les automates réalisés par le dieu forgeron Héphaďstos : des trépieds munis de roues en or, capables de porter des objets jusqu’ŕ l’Olympe et de revenir seuls dans la demeure du dieu ; ou encore, deux servantes forgées en or qui l’assistent dans sa tâche. De męme, le Géant de bronze Talos, gardien des rivages de la Crčte, était parfois considéré comme une śuvre du dieu.
Vitruve, architecte romain, décrit l’existence entre le iiie et le ier sičcle avant notre čre, d’une école d’ingénieurs fondée par Ctesibius ŕ Alexandrie, et concevant des mécanismes destinés ŕ l’amusement tels des corbeaux qui chantaient. Héron L'Ancien décrit dans son traité « Automates », un carrousel animé grâce ŕ la vapeur et considéré comme anticipant les machines ŕ vapeur. Les automates disparaissent ensuite jusqu’ŕ la fin du Moyen Âge. On a pręté ŕ Roger Bacon la conception d'automates doués de la parole; en fait, probablement de mécanismes simulant la prononciation de certains mots simples.
Léonard de Vinci a construit en 1515 un automate en forme de lion pour amuser le roi de France, François I77. Gio Battista Aleotti et Salomon de Caus, eux, ont construit des oiseaux artificiels et chantants, des flűtistes mécaniques, des nymphes, des dragons et des satyres animés pour égayer des fętes aristocratiques, des jardins et des grottes. René Descartes, lui, aurait conçu en 1649 un automate qu’il appelait « ma fille Francine ». Il conduit par ailleurs une réflexion d’un modernisme étonnant sur les différences entre la nature des automates, et celles d’une part des animaux (pas de différence) et d’autre part celle des hommes (pas d’assimilation). Ces analyses en font le précurseur méconnu d’un des principaux thčmes de la science-fiction : l'indistinction entre le vivant et l’artificiel, entre les hommes et les robots, les androďdes ou les intelligences artificielles.

Le canard artificiel de Vaucanson (1738).
Jacques de Vaucanson a construit en 1738 un « canard artificiel de cuivre doré, qui boit, mange, cancane, barbote et digčre comme un vrai canard ». Il était possible de programmer les mouvements de cet automate, grâce ŕ des pignons placés sur un cylindre gravé, qui contrôlaient des baguettes traversant les pattes du canard. L’automate a été exposé pendant plusieurs années en France, en Italie et en Angleterre, et la transparence de l’abdomen permettait d’observer le mécanisme interne. Le dispositif permettant de simuler la digestion et d’expulser une sorte de bouillie verte fait l’objet d’une controverse. Certains commentateurs estiment que cette bouillie verte n’était pas fabriquée ŕ partir des aliments ingérés, mais préparée ŕ l’avance. D’autres estiment que cet avis n’est fondé que sur des imitations du canard de Vaucanson. Malheureusement, l’incendie du Musée de Nijni Novgorod en Russie vers 1879 détruisit cet automate.
Les artisans Pierre et Louis Jaquet-Droz fabriqučrent parmi les meilleurs automates fondés sur un systčme purement mécanique, avant le développement des dispositifs électromécaniques. Certains de ces automates, par un systčme de cames multiples, étaient capables d'écrire un petit billet (toujours le męme). Enfin, Les Contes d'Hoffmann (et ballet) L'Homme au sable décrit une poupée mécanique dont s'éprend le héros.
Pensée automatique[modifier | modifier le code]
Parmi les premiers essais de formalisation de la pensée, les tentatives suivantes peuvent ętre citées :
Raymond Lulle, missionnaire, philosophe, et théologien espagnol du xiiie sičcle, a fait la premičre tentative pour engendrer des idées par un systčme mécanique. Il combinait aléatoirement des concepts grâce ŕ une sorte de rčgle ŕ calcul, un zairja, sur laquelle pivotaient des disques concentriques gravés de lettres et de symboles philosophiques. Il baptisa sa méthode Grand Art (Ars Magna), fondée sur l’identification de concepts de base, puis leur combinaison mécanique soit entre eux, soit avec des idées connexes. Raymond Lulle appliqua sa méthode ŕ la métaphysique, puis ŕ la morale, ŕ la médecine et ŕ l’astrologie. Mais il n’utilisait que la logique déductive, ce qui ne permettait pas ŕ son systčme d’acquérir un apprentissage, ni davantage de remettre en cause ses principes de départ : seule la logique inductive le permet.
Gottfried Wilhelm Leibniz, au xviie sičcle, a imaginé un calcul pensant (calculus rationator), en assignant un nombre ŕ chaque concept. La manipulation de ces nombres aurait permis de résoudre les questions les plus difficiles, et męme d’aboutir ŕ un langage universel. Leibniz a toutefois démontré que l’une des principales difficultés de cette méthode, également rencontrée dans les travaux modernes sur l’intelligence artificielle, est l’interconnexion de tous les concepts, ce qui ne permet pas d’isoler une idée de toutes les autres pour simplifier les problčmes liés ŕ la pensée.
George Boole a inventé la formulation mathématique des processus fondamentaux du raisonnement, connue sous le nom d’algčbre de Boole. Il était conscient des liens de ses travaux avec les mécanismes de l’intelligence, comme le montre le titre de son principal ouvrage paru en 1854 : Les lois de la pensée (The laws of thought), sur l’algčbre booléenne.
Gottlob Frege perfectionna le systčme de Boole en formalisant le concept de prédicat, qui est une entité logique soit vraie, soit fausse (toute maison a un propriétaire), mais contenant des variables non logiques, n’ayant en soit aucun degré de vérité (maison, propriétaire). Cette formalisation eut une grande importance puisqu’elle permit de démontrer des théorčmes généraux, simplement en appliquant des rčgles typographiques ŕ des ensembles de symboles. La réflexion en langage courant ne portait plus que sur le choix des rčgles ŕ appliquer. Par ailleurs, l’utilisateur joue un rôle important puisqu'il connaît le sens des symboles qu’il a inventés et ce sens78 n'est pas toujours formalisé, ce qui ramčne au problčme de la signification en intelligence artificielle, et de la subjectivité des utilisateurs.
Bertrand Russell et Alfred North Whitehead publičrent au début du xxe sičcle un ouvrage intitulé Principia mathematica, dans lequel ils résolvent des contradictions internes ŕ la théorie de Gottlob Frege. Ces travaux laissaient espérer d’aboutir ŕ une formalisation complčte des mathématiques.
Kurt Gödel démontre au contraire que les mathématiques resteront une construction ouverte, en publiant en 1931 un article intitulé « Des propositions formellement indécidables contenues dans les Principia mathematica et autres systčmes similaires ». Sa démonstration est qu’ŕ partir d’une certaine complexité d’un systčme, on peut y créer plus de propositions logiques qu’on ne peut en démontrer vraies ou fausses. L’arithmétique, par exemple, ne peut trancher par ses axiomes si on doit accepter des nombres dont le carré soit -1. Ce choix reste arbitraire et n’est en rien lié aux axiomes de base. Le travail de Gödel suggčre qu’on pourra créer ainsi un nombre arbitraire de nouveaux axiomes, compatibles avec les précédents, au fur et ŕ mesure qu’on en aura besoin. Si l'arithmétique est démontrée incomplčte, le calcul des prédicats (logique formelle) est au contraire démontré par Gödel comme complet.
Alan Turing invente des machines abstraites et universelles (rebaptisées les machines de Turing), dont les ordinateurs modernes sont considérés comme des concrétisations. Il démontre l’existence de calculs qu’aucune machine ne peut faire (un humain pas davantage, dans les cas qu'il cite), sans pour autant que cela constitue pour Turing un motif pour douter de la faisabilité de machines pensantes répondant aux critčres du test de Turing.
Irving John Good79, Myron Tribus et E.T. Jaynes ont décrit de façon trčs claire les principes assez simples d’un robot ŕ logique inductive utilisant les principes de l’inférence bayésienne pour enrichir sa base de connaissances sur la base du Théorčme de Cox-Jaynes. Ils n’ont malheureusement pas traité la question de la façon dont on pourrait stocker ces connaissances sans que le mode de stockage entraîne un biais cognitif. Le projet est voisin de celui de Raymond Lulle, mais fondé cette fois-ci sur une logique inductive, et donc propre ŕ résoudre quelques problčmes ouverts.
Robot ŕ logique inductive80.
Des chercheurs comme Alonzo Church ont posé des limites pratiques aux ambitions de la raison, en orientant la recherche (Herbert Simon, Michael Rabin, Stephen Cook) vers l’obtention des solutions en temps fini, ou avec des ressources limitées, ainsi que vers la catégorisation des problčmes selon des classes de difficulté (en rapport avec les travaux de Cantor sur l’infini)[réf. souhaitée].
