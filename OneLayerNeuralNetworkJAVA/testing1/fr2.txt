Utilité[modifier | modifier le code]
Les réseaux de neurones, en tant que systčmes capables d'apprendre, mettent en śuvre le principe de l'induction, c’est-ŕ-dire l'apprentissage par l'expérience. Par confrontation avec des situations ponctuelles, ils infčrent un systčme de décision intégré dont le caractčre générique est fonction du nombre de cas d'apprentissages rencontrés et de leur complexité par rapport ŕ la complexité du problčme ŕ résoudre. Par opposition, les systčmes symboliques capables d'apprentissage, s'ils implémentent également l'induction, le font sur base de la logique algorithmique, par complexification d'un ensemble de rčgles déductives (Prolog par exemple).
Grâce ŕ leur capacité de classification et de généralisation, les réseaux de neurones sont généralement utilisés dans des problčmes de nature statistique, tels que la classification automatique de codes postaux ou la prise de décision concernant un achat boursier en fonction de l'évolution des cours. Autre exemple, une banque peut créer un jeu de données sur les clients qui ont effectué un emprunt constitué : de leur revenu, de leur âge, du nombre d’enfants ŕ charge… et s’il s’agit d’un bon client. Si ce jeu de données est suffisamment grand, il peut ętre utilisé pour l’entraînement d’un réseau de neurones. La banque pourra alors présenter les caractéristiques d’un potentiel nouveau client, et le réseau répondra s’il sera bon client ou non, en généralisant ŕ partir des cas qu’il connaît.
Si le réseau de neurones fonctionne avec des nombres réels, la réponse traduit une probabilité de certitude. Par exemple : 1 pour « sűr qu’il sera un bon client », -1 pour « sűr qu’il sera mauvais client », 0 pour « aucune idée », 0,9 pour « presque sűr qu’il sera bon client ».
Le réseau de neurones ne fournit pas toujours de rčgle exploitable par un humain. Le réseau reste souvent une boîte noire qui fournit une réponse quand on lui présente une donnée, mais le réseau ne fournit pas de justification facile ŕ interpréter.
Les réseaux de neurones sont réellement utilisés, par exemple :
pour la classification d’espčces animales par espčce étant donnée une analyse ADN.
reconnaissance de motif ; par exemple pour la reconnaissance optique de caractčres (OCR), et notamment par les banques pour vérifier le montant des chčques, par La Poste pour trier le courrier en fonction du code postal, etc. ; ou bien encore pour le déplacement automatisé de robots mobiles autonomes.
approximation d’une fonction inconnue.
modélisation accélérée d’une fonction connue mais trčs complexe ŕ calculer avec exactitude ; par exemple certaines fonctions d’inversions utilisées pour décoder les signaux de télédétection émis par les satellites et les transformer en données sur la surface de la mer.
estimations boursičres :
apprentissage de la valeur d’une entreprise en fonction des indices disponibles : bénéfices, endettements ŕ long et court terme, chiffre d’affaires, carnet de commandes, indications techniques de conjoncture. Ce type d’application ne pose pas en général de problčme
tentatives de prédiction sur la périodicité des cours boursiers. Ce type de prédiction est trčs contesté pour deux raisons, l’une étant qu'il n'est pas évident que le cours d’une action ait de façon tout ŕ fait convaincante un caractčre périodique (le marché anticipe en effet largement les hausses comme les baisses prévisibles, ce qui applique ŕ toute périodicité éventuelle une variation de période tendant ŕ la rendre difficilement fiable), et l’autre que l’avenir prévisible d’une entreprise détermine au moins aussi fortement le cours de son action, si ce n'est plus encore que peut le faire son passé ; les cas de Pan Am, Manufrance ou IBM permettent de s’en convaincre.
modélisation de l'apprentissage et amélioration des techniques de l'enseignement.
en météorologie, pour la classification de conditions atmosphériques et la prévision statistique du temps.
en auscultation des ouvrages hydrauliques, pour la compréhension physique des phénomčnes de déplacements, sous-pressions et débits de fuite.
Limites[modifier | modifier le code]
Les réseaux de neurones artificiels ont besoin de cas réels servant d’exemples pour leur apprentissage (on appelle cela la base d'apprentissage). Ces cas doivent ętre d’autant plus nombreux que le problčme est complexe et que sa topologie est peu structurée. Ainsi on peut optimiser un systčme neuronal de lecture de caractčres en utilisant le découpage manuel d’un grand nombre de mots écrits ŕ la main par de nombreuses personnes. Chaque caractčre peut alors ętre présenté sous la forme d’une image brute, disposant d’une topologie spatiale ŕ deux dimensions, ou d’une suite de segments presque tous liés. La topologie retenue, la complexité du phénomčne modélisé, et le nombre d’exemples doivent ętre en rapport. Sur un plan pratique, cela n’est pas toujours facile car les exemples peuvent ętre soit en quantité absolument limitée ou trop onéreux ŕ collecter en nombre suffisant.
Il y a des problčmes qui se traitent bien avec les réseaux de neurones, en particulier ceux de classification en domaines convexes (c’est-ŕ-dire tels que si des points A et B font partie du domaine, alors tout le segment AB en fait partie aussi). Des problčmes comme « Le nombre d’entrées ŕ 1 (ou ŕ zéro) est-il pair ou impair ? » se résolvent en revanche trčs mal : pour affirmer de telles choses sur 2 puissance N points, si on se contente d’une approche naďve mais homogčne, il faut précisément N-1 couches de neurones intermédiaires, ce qui nuit ŕ la généralité du procédé.
Un exemple caricatural, mais significatif est le suivant : disposant en entrée du seul poids d'une personne, le réseau doit déterminer si cette personne est une femme ou bien un homme. Les femmes étant statistiquement un peu plus légčres que les hommes, le réseau fera toujours un peu mieux qu'un simple tirage au hasard : cet exemple dépouillé indique la simplicité et les limitations de ces modčles mais il montre également comment l'étendre : l'information « port d'une jupe », si on l'ajoute, aurait clairement un coefficient synaptique plus grand que la simple information de poids.
Opacité[modifier | modifier le code]
Les réseaux complexes de neurones artificiels ne peuvent généralement pas expliquer eux-męmes leur façon de « penser ». Les calculs aboutissant ŕ un résultat sont cachés pour ceux qui ont créé le réseau neuronal7. Une « neuroscience de l'Intelligence artificielle » a donc été créée pour explorer la boîte noire que constitue ces réseaux de neurones, science qui pourrait augmenter le degré de confiance dans les résultats produits par ces réseaux ou les intelligences artificiels qui les utilisent7.
Modčle[modifier | modifier le code]
Structure du réseau[modifier | modifier le code]

Structure d'un neurone artificiel. Le neurone calcule la somme de ses entrées puis cette valeur passe ŕ travers la fonction d'activation pour produire sa sortie.
Un réseau de neurones est en général composé d'une succession de couches dont chacune prend ses entrées sur les sorties de la précédente. Chaque couche (i) est composée de Ni neurones, prenant leurs entrées sur les Ni-1 neurones de la couche précédente. Ŕ chaque synapse est associé un poids synaptique, de sorte que les Ni-1 sont multipliés par ce poids, puis additionnés par les neurones de niveau i, ce qui est équivalent ŕ multiplier le vecteur d'entrée par une matrice de transformation. Mettre l'une derričre l'autre les différentes couches d'un réseau de neurones reviendrait ŕ mettre en cascade plusieurs matrices de transformation et pourrait se ramener ŕ une seule matrice, produit des autres, s'il n'y avait ŕ chaque couche, la fonction de sortie qui introduit une non linéarité ŕ chaque étape. Ceci montre l'importance du choix judicieux d'une bonne fonction de sortie : un réseau de neurones dont les sorties seraient linéaires n'aurait aucun intéręt.
Au-delŕ de cette structure simple, le réseau de neurones peut également contenir des boucles qui en changent radicalement les possibilités mais aussi la complexité. De la męme façon que des boucles peuvent transformer une logique combinatoire en logique séquentielle, les boucles dans un réseau de neurones transforment un simple dispositif de reconnaissance d'entrées en une machine complexe capable de toutes sortes de comportements.
Fonction de combinaison[modifier | modifier le code]
Considérons un neurone quelconque.
Il reçoit des neurones en amont un certain nombre de valeurs via ses connexions synaptiques, et il produit une certaine valeur en utilisant une fonction de combinaison. Cette fonction peut donc ętre formalisée comme étant une fonction vecteur-ŕ-scalaire, notamment :
Les réseaux de type MLP (multi-layer perceptron) calculent une combinaison linéaire des entrées, c’est-ŕ-dire que la fonction de combinaison renvoie le produit scalaire entre le vecteur des entrées et le vecteur des poids synaptiques.
Les réseaux de type RBF (radial basis function) calculent la distance entre les entrées, c’est-ŕ-dire que la fonction de combinaison renvoie la norme euclidienne du vecteur issu de la différence vectorielle entre les vecteurs d’entrées.
Fonction d’activation[modifier | modifier le code]
La fonction d’activation (ou fonction de seuillage, ou encore fonction de transfert) sert ŕ introduire une non-linéarité dans le fonctionnement du neurone.
Les fonctions de seuillage présentent généralement trois intervalles :
en dessous du seuil, le neurone est non-actif (souvent dans ce cas, sa sortie vaut 0 ou -1) ;
aux alentours du seuil, une phase de transition ;
au-dessus du seuil, le neurone est actif (souvent dans ce cas, sa sortie vaut 1).
Des exemples classiques de fonctions d’activation sont :
La fonction sigmoďde.
La fonction tangente hyperbolique.
La fonction de Heaviside.
La logique bayésienne, dont le théorčme de Cox-Jaynes formalise les questions d’apprentissage, fait intervenir aussi une fonction en S qui revient de façon récurrente : {\displaystyle ev(p)=10\log \left({\frac {p}{1-p}}\right)} ev(p)=10\log \left({\frac  {p}{1-p}}\right)
Propagation de l’information[modifier | modifier le code]
Ce calcul effectué, le neurone propage son nouvel état interne sur son axone. Dans un modčle simple, la fonction neuronale est simplement une fonction de seuillage : elle vaut 1 si la somme pondérée dépasse un certain seuil ; 0 sinon. Dans un modčle plus riche, le neurone fonctionne avec des nombres réels (souvent compris dans l’intervalle [0,1] ou [-1,1]). On dit que le réseau de neurones passe d'un état ŕ un autre lorsque tous ses neurones recalculent en parallčle leur état interne, en fonction de leurs entrées.
Apprentissage[modifier | modifier le code]
Base théorique[modifier | modifier le code]
La notion d’apprentissage, bien que connue déjŕ depuis Sumer, n’est pas modélisable dans le cadre de la logique déductive : celle-ci en effet procčde ŕ partir de connaissances déjŕ établies dont on tire des connaissances dérivées. Or il s’agit ici de la démarche inverse : par observations limitées, tirer des généralisations plausibles : c'est un procédé par induction.
La notion d’apprentissage recouvre deux réalités souvent traitées de façon successive :
mémorisation : le fait d’assimiler sous une forme dense des exemples éventuellement nombreux,
généralisation : le fait d’ętre capable, grâce aux exemples appris, de traiter des exemples distincts, encore non rencontrés, mais similaires.
Dans le cas des systčmes d’apprentissage statistique, utilisés pour optimiser les modčles statistiques classiques, réseaux de neurones et automates markoviens, c’est la généralisation qui est l’objet de toute l’attention.
Cette notion de généralisation est traitée de façon plus ou moins complčte par plusieurs approches théoriques.
La généralisation est traitée de façon globale et générique par la théorie de la régularisation statistique introduite par Vladimir Vapnik. Cette théorie, développée ŕ l’origine en Union soviétique, s’est diffusée en Occident depuis la chute du mur de Berlin. La théorie de la régularisation statistique s’est diffusée trčs largement parmi ceux qui étudient les réseaux de neurones en raison de la forme générique des courbes d’erreurs résiduelles d’apprentissage et de généralisation issues des procédures d’apprentissage itératives telles que les descentes de gradient utilisées pour l’optimisation des perceptrons multi-couches. Ces formes génériques correspondent aux formes prévues par la théorie de la régularisation statistique ; cela vient du fait que les procédures d’apprentissage par descente de gradient, partant d’une configuration initiale des poids synaptiques explorent progressivement l’espace des poids synaptiques possibles ; on retrouve alors la problématique de l’augmentation progressive de la capacité d’apprentissage, concept fondamental au cśur de la théorie de la régularisation statistique.
La généralisation est aussi au cśur de l’approche de l'inférence bayésienne, enseignée depuis plus longtemps. Le théorčme de Cox-Jaynes fournit ainsi une base importante ŕ un tel apprentissage, en nous apprenant que toute méthode d’apprentissage est soit isomorphe aux probabilités munies de la relation de Bayes, soit incohérente. C’est lŕ un résultat extręmement fort, et c’est pourquoi les méthodes bayésiennes sont largement utilisées dans le domaine.
Classe de problčmes solubles[modifier | modifier le code]
En fonction de la structure du réseau, différents types de fonction sont approchables grâce aux réseaux de neurones :
Fonctions représentables par un perceptron[modifier | modifier le code]
Un perceptron (un réseau ŕ une unité) peut représenter les fonctions booléennes suivantes : and, or, nand, nor mais pas le xor. Comme toute fonction booléenne est représentable ŕ l'aide de ces fonctions, un réseau de perceptrons est capable de représenter toutes les fonctions booléennes. En effet les fonctions nand et nor sont dites universelles : on peut par combinaison de l'une de ces fonctions représenter toutes les autres.